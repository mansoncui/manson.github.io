<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux检查服务器性能工具]]></title>
    <url>%2F2019%2F06%2F18%2Flinux%E6%93%8D%E4%BD%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2Flinux%E6%A3%80%E6%9F%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[linux检查服务器性能工具1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586871.出现弹窗后,在蓝色方框内,字母为OEM的则正版或RETAIL为零售版也是正版; 2.如果出现的字母是VOLUME则为批量激活,即为盗版vmstat #查询全局资源使用情况选项:-a, --active active/inactive memory # 显示活跃和非活跃内存-f, --forks number of forks since boot # 显示从系统启动至今的fork数量 -m, --slabs slabinfo # 显示slabinfo-n, --one-header do not redisplay header # 只在开始时显示一次字段名称-s, --stats event counter statistics # 显示内存相关的统计信息及多种系统活动数量-d, --disk disk statistics # 显示磁盘相关统计信息-D, --disk-sum summarize disk statistics # 显示磁盘的总计信息-p, --partition &lt;dev&gt; partition specific statistics # 显示指定磁盘分区统计信息-S, --unit &lt;char&gt; define display unit # 使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）-w, --wide wide output # 更宽的显示信息-t, --timestamp show timestamp # 显示时间-h, --help display this help and exit-V, --version output version information and exitpidstat #查询某个进程资源使用情况（yum install sysstat）选项:-u：默认的参数，显示各个进程的cpu使用统计-r：显示各个进程的内存使用统计-d：显示各个进程的IO使用情况-p：指定进程号-w：显示每个进程的上下文切换情况-t：显示选择任务的线程的统计信息外的额外信息-T &#123; TASK | CHILD | ALL &#125;这个选项指定了pidstat监控的。TASK表示报告独立的task，CHILD关键字表示报告进程下所有线程统计信息。ALL表示报告独立的task和task下面的所有线程。注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。-V：版本号-h：在一行上显示了所有活动，这样其他程序可以容易解析。-I：在SMP环境，表示任务的CPU使用率/内核数量-l：显示命令名和所有参数案列:pidstat 和 pidstat -u -p ALL 是等效的pidstat 默认显示了所有进程的cpu使用率dstat #同时查看CPU和IO资源使用情况（yum install -y dstat）选项:-c：显示CPU系统占用，用户占用，空闲，等待，中断，软件中断等信息。-C：当有多个CPU时候，此参数可按需分别显示cpu状态，例：-C 0,1 是显示cpu0和cpu1的信息。-d：显示磁盘读写数据大小。-D hda,total：include hda and total。-n：显示网络状态。-N eth1,total：有多块网卡时，指定要显示的网卡。-l：显示系统负载情况。-m：显示内存使用情况。-g：显示页面使用情况。-p：显示进程状态。-s：显示交换分区使用情况。-S：类似D/N。-r：I/O请求情况。-y：系统状态。--ipc：显示ipc消息队列，信号等信息。--socket：用来显示tcp udp端口状态。-a：此为默认选项，等同于-cdngy。-v：等同于 -pmgdsc -D total。--output 文件：此选项也比较有用，可以把状态信息以csv的格式重定向到指定的文件中，以便日后查看。例：dstat --output /root/dstat.csv &amp; 此时让程序默默的在后台运行并把结果输出到/root/dstat.csv文件中。starce #跟踪某一进程和硬件进行交互过程选项:-o 把strace追踪数据追加到一个文本中-p 指定进程pid-t -tt 在每行输出前加上时间戳，-tt是更详细时间-r 展示系统调用之间的相对时间戳-c 是对输出数据格式化(是以整洁方式展示)-e 选项仅仅被用来展示特定的系统调用（例如，open，write等等）寻找被程序读取的配置文件:案列:strace php 2&gt;&amp;1 | grep php.inipidstat -d 选项是展示I/O 统计数据，用strace追踪某一个进程，以root用户追踪某一个进程时显示没有权限，用ps检查该进程是否存在，或者看下该进程当前状态案列:pidstat -d 1 20-d 是展示I/O统计数据1 20 表示1s内展示20组数据pstree -aps 3084选项详解:-a 表示输出命令选项p 表示进程pids 表示指定进程的父进程perf record -gperf report stress #压力测试工具]]></content>
      <categories>
        <category>linux操作性能优化</category>
      </categories>
      <tags>
        <tag>linux检查服务器性能工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab]]></title>
    <url>%2F2019%2F06%2F18%2Fgitlab%2Fgitlab%2F</url>
    <content type="text"><![CDATA[gitlab 迁移 故障 总结gitlab 迁移123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108升级gitlab服务和服务器配置准备:a、关闭gitlab服务中(sidekiq和unicorn)、nginx服务和docker服务b、对gitlab服务备份命令:gitlab-rake gitlab:backup:createc、关闭gitlab所有服务，在阿里云控制台对系统盘做快照(恢复方式有两种:对快照做成镜像恢复系统，按量付费ECS机器)d、gitlab服务升级:备份gitlab相关配置文件目录:/etc/gitlab,/opt/gitlab/embedded/service/gitlab-shell/hooks(hooks文件中:pre-receive是本地推送到远端仓库使用的，post-receive:是远端仓库使用runner调用的文件，新版本:11.8和之前就有所改变，不然不能触发runner和CI文件)e、所有服务已关闭，对ECS服务器进行升级 #新服务器gitlab环境部署(迁移前和当前新gitlab-ce环境必须保持一致，不然会报错)修改/etc/sysctl.conf加上vm.overcommit_memory = 1, Linux内核会根据参数vm.overcommit_memory参数的设置决定是否放行。修改完执行sysctl -pvm.overcommit_memory = 1，直接放行vm.overcommit_memory = 0：则比较 此次请求分配的虚拟内存大小和系统当前空闲的物理内存加上swap，决定是否放行。vm.overcommit_memory = 2：则会比较进程所有已分配的虚拟内存加上此次请求分配的虚拟内安装php客户端，用于php语法检测备份hooks目录，存放钩子文件1、安装openresty环境,同步相关数据,如下所示:/kuaibao/server/nginx/conf/nginx.conf/kuaibao/server/nginx/conf/vhosts/kuaibao/server/nginx/conf/key/etc/gitlab/gitlab.rb #gitlab配置文件/etc/gitlab/gitlab-secrets.json #gitlab秘钥文件/etc/gitlab/ssl #同步https存放秘钥目录2、安装gitlab-ce版本yum -y install policycoreutils-python curl policycoreutils openssh-server openssh-clients postfix patch zlib-devel perl perl-devel #安装gitlab-ce依赖包rpm -ivh gitlab-ce-11.7.0-ce.0.el7.x86_64.rpm #安装gitlab-ce cat /etc/postfix/main.cf #修改postfix发邮件配置inet_interfaces = localtion 修改成 inet_interfaces = allsystemctl start postfix &amp;&amp; systemctl enable postfix #开启发邮件gitlab-ctl reconfigure #初始化gitlab配置3、部署docker环境(docker环境中runner可以和gitlab服务分开分开)yum install -y yum-utils device-mapper-persistent-data lvm2 #安装yum依赖yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #配置yum源yum makecache fast #生成yum本地缓存yum -y install docker-cesystemctl start docker &amp;&amp; systemctl enable docker cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://d5ma8gvx.mirror.aliyuncs.com&quot;]&#125;cat /root/.docker/config.json #修改服务器pull镜像认证信息##导出镜像并导入到新服务器上[root@izbp19hcysthc34tbzp53bz ~]# docker save -o code-push-cli.tar bbe405d4b00c[root@izbp19hcysthc34tbzp53bz ~]# docker save -o php-ci.tar d25001fdfaed[root@iZbp12yr7w4vdshygsnusjZ ~]# docker tag bbe405d4b00c cqingwang/code-push-cli:v5[root@iZbp12yr7w4vdshygsnusjZ ~]# docker tag d25001fdfaed registry.cn-hangzhou.aliyuncs.com/kuaibao/php-ci:latest[root@iZbp12yr7w4vdshygsnusjZ ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcqingwang/code-push-cli v5 bbe405d4b00c 2 months ago 118MBregistry.cn-hangzhou.aliyuncs.com/kuaibao/php-ci latest d25001fdfaed 12 months ago 261MBsystemctl daemon-reload &amp;&amp; systemctl restart docker4、备份恢复gitlab数据(备份代码需要关闭:sidekiq,unicorn和nginx服务)备份老gitlab上数据:gitlab-rake gitlab:backup:create &gt;&gt;/opt/gitlab_backup.log 2&gt;&amp;1 在新gitlab服务器上恢复数据(恢复代码不需要关闭gitlab服务):备份数据放到gitlab默认备份目录下:/var/opt/gitlab/backups 修改文件名: mv 1550593467_2019_02_20_11.5.0_gitlab_backup.tar 1550593467_gitlab_backup.targitlab-rake gitlab:backup:restore BACKUP=1550593467 #恢复数据目录(会出现两次交互，都选择yes)gitlab-ctl stop #关闭所有服务gitlab-ctl start #开启所有服务systemctl enable gitlab-runsvdir #设置gitlab开机启动gitlab-rake gitlab:check SANITIZE=true #检查数据恢复情况#查看gitlab所有的日志gitlab-ctl tail # 拉取/var/log/gitlab下子目录的日志sudo gitlab-ctl tail gitlab-rails# 拉取某个指定的日志文件sudo gitlab-ctl tail nginx/gitlab_error.logsystemctl restart docker /kuaibao/server/nginx/conf/nginx/sbin/nginx -t #检查nginx配置/kuaibao/server/nginx/conf/nginx/sbin/nginx #开启nginx服务# chrome访问gitlab新服务器，并测试# 小版本升级注意事项(比如:11.5至11.8)1、备份:/etc/gitlab/和/opt/gitlab/embedded/service/gitlab-shell/hooks/目录2、升级小版本不需要关闭gitlab服务 gitlab配置和生产环境中遇到问题问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129git命令参考网址:http://rogerdudler.github.io/git-guide/index.zh.html1、项目归档（项目只有读权限）projetc-&gt;Setting-&gt;General-&gt;Advanced-&gt;archive project 2、开启分支保护和tags保护（和每组设置变量相关）选中某个项目-&gt;Settings-&gt;Repository-&gt;Protected Tags-&gt;创建维护者(20*)3、关闭gitlab注册功能Admin Area-&gt;Settings-&gt;Sign-up restrictions（勾去掉，就是取消注册）4、开启二次验证Admin Area-&gt;Settings-&gt;Sign-in restrictions(开启二次验证)5、设置CICD秘钥设置选择项目-&gt;Settings-&gt;CICD-&gt;Environment variables(这里面添加变量:公私钥变量名设置ID_RSA和ID_RSA_PUB)6、浏览器进行合并时需要先执行:git pull 或git fetch7、配置runner单独项目使用runnerproject(选择项目)-&gt;Settings-&gt;CICD-&gt;Runner（复制里面key）设置share runnerAdmin Area-&gt;Settings-&gt;CICD-&gt;Runner（复制里面key）8、docker登录信息本地存储[root@izbp19hcysthc34tbzp53bz ~]# cat /root/.docker/config.json &#123; &quot;auths&quot;: &#123; &quot;registry.cn-hangzhou.aliyuncs.com&quot;: &#123; &quot;auth&quot;: &quot;xxxxxxx密码xxxxxxxxxx&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/17.09.0-ce (linux)&quot; &#125;&#125;9、以下信息是注册runner时生成信息concurrent = 1check_interval = 0[session_server] session_timeout = 1800[[runners]] name = &quot;mansoncui-test&quot; url = &quot;https://gitlab.XXXXXX.com&quot; token = &quot;XXXXXX&quot; executor = &quot;docker&quot; [runners.docker] pull_policy = &quot;if-not-present&quot; #判断镜像是否从本地取 tls_verify = false image = &quot;php&quot; privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [&quot;/cache&quot;] shm_size = 0 [runners.cache] [runners.cache.s3] [runners.cache.gcs]9、gitlab-ci文件(注意文件中域名修改)$ cat .gitlab-ci.ymlimage: $&#123;IMAGE&#125; #在groups中设置组变量stages: - deployvariables: PROJECT_NAME: mansoncui CI_DEBUG_TRACE: &quot;true&quot; #开启debug模式 #prod env PROD_ADDRES_IP: &quot;192.168.1.120&quot; PROD_ADDRES_PORT: &quot;22&quot; PROD_DOMAIN: &quot;http://gitlab.mansoncui.com&quot; #gitlab GITLAB_ADDRES_PORT: &quot;22&quot; GITLAB_ADDRES_IP: &quot;gitlab.mansoncui.com&quot;before_script: - echo &quot;$&#123;DEBUG&#125; $&#123;IMAGE&#125;&quot; #打印变量 - if [ &quot;$&#123;DEBUG&#125;&quot; == &quot;TRUE&quot; ];then sleep 600;fi #设置项目变量，调试CI文件 - if [ &quot;$&#123;PROJECT_NAME&#125;&quot; == &quot;&quot; ]; then echo &quot;$&#123;PROJECT_NAME&#125; 没有定义， jobs异常退出。。。&quot;; exit 1;fi #判断变量是否存在，不存直接退出 - mkdir -p ~/.ssh - echo &quot;118.126.66.60 www.mansoncui.com&quot; &gt;&gt; /etc/hosts - echo &quot;$ID_RSA_PUB&quot; &gt; ~/.ssh/id_rsa.pub - echo &quot;$ID_RSA&quot; &gt; ~/.ssh/id_rsa &amp;&amp; chmod 0600 ~/.ssh/id_rsa - ssh-keyscan -H -t ecdsa -p $PROD_ADDRES_PORT $PROD_ADDRES_IP &gt;&gt; ~/.ssh/known_hostsdeploy_prod: stage: deploy script: - rsync -avztH -e &quot;ssh -p $PROD_ADDRES_PORT&quot; --exclude &quot;.git&quot; --delete ./ $PROD_ADDRES_IP:/xxxx/www/$&#123;PROJECT_NAME&#125;/ only: - tags except: - /(?i:rc)$/ tags: - vpc-share-tags environment: name: prod url: $DOMAINsendmail: stage: deploy script: - if [ ! -f sendmail.py ]; then wget -O sendmail.py https://www.xxxx.com/gitlab/xxxxx.py; fi - python ./sendmail.py only: - tags except: - /(?i:rc)$/ tags: - vpc-share-tags allow_failure: false]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git]]></title>
    <url>%2F2019%2F06%2F17%2Fgit%2Fgit%2F</url>
    <content type="text"><![CDATA[git1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681、解决文件已经添加到暂存区进行回退 git reset HEAD readme.txt(文件) #取消暂存区文件修改 git status #查看当前文件状态 git checkout -- readme.txt #回退到git add之前状态 git log -n10 --oneline #显示最近十次提交日志 git diff old_id new_id --name-status #对比两次提交和文件修改及状态2、查看git提交日志 git log参数详解: -p 按补丁格式显示每个更新之间的差异。 --stat 显示每次更新的文件修改统计信息。 --shortstat 只显示 --stat 中最后的行数修改添加移除统计。 --name-only 仅在提交信息后显示已修改的文件清单。 --name-status 显示新增、修改、删除的文件清单。 --abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。 --relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。 --graph 显示 ASCII 图形表示的分支合并历史。 --pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。 -(n) 仅显示最近的 n 条提交 --since, --after 仅显示指定时间之后的提交。 --until, --before 仅显示指定时间之前的提交。 --author 仅显示指定作者相关的提交。 --committer 仅显示指定提交者相关的提交。 --grep 仅显示含指定关键字的提交 -S 仅显示添加或移除了某个关键字的提交++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ git log filename #查看filename文件commit记录 git log -p filename #显示每次提交的diff git log --pretty=format:&quot;%cn committed %h on %cd&quot; #指定日志格式(%cn作者名字，%h缩略标识，%cd提交日期) git log --author=&quot;manson&quot; git log --pretty=&quot;%an - %s&quot; --author=cuibobo --since=&quot;2018-10-01&quot; --before=&quot;2018-12-27&quot; --oneline #指定格式和日期进行日志查询 git log #命令显示从最近到最远的提交日志，如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline git reset --hard HEAD^ #用HEAD表示当前版本（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100 git reset --hard commit_id #通过commit id来回溯 git reflog #Git提供了一个命令git reflog用来记录你的每一次命令 HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id。 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 git remote add origin git@server-name:path/repo-name.git #添加远程仓库 git push -u origin master #第一次推送master分支的所有内容； git push origin master #提交以后，推送最新修改3、git使用分支 Git鼓励大量使用分支： 查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt;4、合并和解决冲突 git log —-graph —-pretty=oneline —abbrev-commit #查看执行日志 git merge abort #放弃合并 git merge —-no-ff -m “描述信息” 分支名 #解决Fast forward删除分支会丢失commit id信息，加-m选项描述信息，因为会产生新commit id 总结:合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。5、解决bug分支前隐藏当前工作目录 工作场景:当前某个分支还未提交，需要解决线上bug: git stash #把当前工作现场&quot;储藏&quot;起来,然后就可以修改bug git stash list #查看工作现场 git stash apply #恢复工作现场，恢复以后stash内容不删除，使用git stash drop来删除 git stash pop #恢复工作目录同时并把stash内容也删除 git stash apply stash@&#123;0&#125; #恢复指定stash 6、git log --pretty=format:&quot;%h - %an, %ar : %s&quot; %H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 -date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 %s 提交说明 -(n) 仅显示最近的 n 条提交 --since, --after 仅显示指定时间之后的提交。 --until, --before 仅显示指定时间之前的提交。 --author 仅显示指定作者相关的提交。 --committer 仅显示指定提交者相关的提交。 git log --pretty=&quot;%h - %s&quot; --author=gitster --since=&quot;2008-10-01&quot; --before=&quot;2008-12-27&quot; --no-merges -- t/ git log --pretty=format:&quot;%cn committed %h on %cd&quot;7、分支作用 分支策略 在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。8、tags创建和推送git tag &lt;tagname&gt;用于新建一个标签，默认为HEAD，也可以指定一个commit id；git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;可以指定标签信息；git tag可以查看所有标签。git push origin &lt;tagname&gt;可以推送一个本地标签；git push origin --tags可以推送全部未推送过的本地标签；git tag -d &lt;tagname&gt;可以删除一个本地标签；git push origin :refs/tags/&lt;tagname&gt;可以删除一个远程标签]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F06%2F12%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式基本语法和案列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091正则就是规则，正则表达式就是能够让我们表达出自己想法的规则grep命令:选项详解:-i 区分大小写匹配-n 显示行号--color 或 --color=auto 高亮显示关键字可以设置别名:alias grep=&apos;grep --color=auto&apos;-c 统计符合条件的总行数，而不打印出行-o 只显示被匹配到的关键字，而不是讲整行内容都输出，一行匹配多个关键字会换行显示-B 显示符合条件的行之前的行，“B” 有before之意-B1 表示显示符合条件的同时还显示之前的1行-B3 表示显示符合条件的同时还显示之前的3行-A 和-B恰恰相反，-A有After之意-w 有word之意，表示搜索的字符串作为一个独立的单词时才会被匹配到-v 和匹配字符串取反的意思-q 表示时静默模式，静默模式下grep不会输出任何信息，无论是否匹配到指定字符串，都不会输出任何字符串，都不会输出任何信息-E 扩展正则表达式&quot;^&quot; 在正则中表示锚定行首&quot;$&quot; 在正则中表示锚定行尾&quot;^$&quot; 在正则中表示空行案列:[root@test-service ~]# grep &quot;^hello&quot; --color test2 #显示已hello开头行hello worldhello.cbbhello[root@test-service ~]# grep -n &quot;^hello&quot; --color test2 #显示已hello开头的行并显示行号1:hello world3:hello.cbb4:hello[root@test-service ~]# grep -n &quot;^$&quot; --color test2 #显示空行和空行行号4:6:&quot;\&lt;&quot;表示锚定词首，&quot;\&gt;&quot;表示锚定词尾&quot;\&lt;与\&gt;&quot; 一起使用,也可以使用\b 锚定词首和词尾案列:[root@test-service ~]# cat test3 hello worldhi hello111111hello.cbb11111hello[root@test-service ~]# grep --color &quot;\&lt;hello&quot; test3hello worldhi hello111111hello.cbb[root@test-service ~]# grep --color &quot;hello\&gt;&quot; test3hello worldhello.cbb11111hello[root@test-service ~]# grep --color &quot;\&lt;hello\&gt;&quot; test3hello worldhello.cbb使用\b 锚定词首和词尾案列:[root@test-service ~]# grep --color &quot;\bhello&quot; test3hello worldhi hello111111hello.cbb[root@test-service ~]# grep --color &quot;hello\b&quot; test3hello worldhello.cbb11111hello[root@test-service ~]# grep --color &quot;\bhello\b&quot; test3hello worldhello.cbb\B 是用来匹配非单词边界的案列:[root@test-service ~]# grep --color &quot;\Bhello&quot; test3 #只要hello不是词首，就会被匹配到,和&quot;\bhello&quot;恰恰相反11111hello[root@test-service ~]# grep --color &quot;hello\B&quot; test3 #只要hello不是词尾就匹配hi hello111111[root@test-service ~]# grep --color &quot;\Bhello\B&quot; test3 #既不是词首也不是词尾，就匹配1111hellocbb总结:^: 表示锚定行首,此字符后面的任意内容必须出现在行首，才能匹配$: 表示锚定行尾,此字符前面的任意内容必须出现在行尾，才能匹配^$: 表示匹配空行,这里所描述的空行表示“回车”，而“空格”或&quot;tab&quot;等都不能算此处所描述的空行^abc$: 表示abc独占一行，会被匹配到\&lt;h或者\b :匹配单词边界，表示锚定词首，其后面的字符必须作为单词首部出现\&gt;或者\b ：匹配单词边界，表示锚定词尾，其前面的字符必须作为单词尾部出现\B: 匹配非单词边界，与\b 正好相反 正则表达式之分组123456789101112131415161718192021222324252627282930313233343536373839正则表达式之分组:案列:[root@test-service ~]# cat test5abefefabefefabefef[root@test-service ~]# grep -n --color &quot;\(abefef\)\&#123;2\&#125;&quot; test5 #&#123;2&#125;是影响括号中一整个字符串2:abefefabefef[root@test-service ~]# grep -n --color &quot;\(ab\(ef\)\&#123;2\&#125;\)\&#123;2\&#125;&quot; test52:abefefabefef以上案列中包含了两组分组符号，最外侧的&quot;\( \)&quot;中又包含了另一个&quot;\( \)&quot;,这就是分组符号的嵌套后向引用:案列:[root@test-service ~]# cat test6Hello world HelloHiiii world Hiiii[root@test-service ~]# grep --color &quot;H.\&#123;4\&#125; world H.\&#123;4\&#125;&quot; test6 Hello world HelloHiiii world Hiiii#第三行是新增也匹配[root@test-service ~]# grep --color &quot;H.\&#123;4\&#125; world H.\&#123;4\&#125;&quot; test6 Hello world HelloHiiii world HiiiiHello world Hiiii#后向应用:在原有的基础之上新增分组[root@test-service ~]# grep --color &quot;\(H.\&#123;4\&#125;\) world \1&quot; test6 Hello world HelloHiiii world Hiiii小结:&quot;\1&quot;表示引用整个正则中第一个分组中的正则所匹配到的结果&quot;\2&quot;表示引用整个正则中第二个分组中的正则所匹配到的结果\(\)表示分组，我们可以将其中的内容当做一个整体，分组可以嵌套\(ab\)表示将ab当做一个整体去处理 awk 格式化123456789101112131415161718192021222324252627282930313233343536主义以下三点:格式化printf和awk中printf不同1）使用printf动作输出的文本不会换行，如果需要换行，可以在对应的&quot;格式替换符&quot;后加入&quot;\n&quot;进行转义。2）使用printf动作时，&quot;指定的格式&quot; 与 &quot;被格式化的文本&quot; 之间，需要用&quot;逗号&quot;隔开。3）使用printf动作时，&quot;格式&quot;中的&quot;格式替换符&quot;必须与 &quot;被格式化的文本&quot; 一一对应案列:[root@test-service ~]# awk -F: &apos;&#123;printf &quot;%s\n%s\n%s\n&quot; , $1,$2,$3&#125;&apos; testrootx0binx1对比以下两个案列不同:[root@test-service ~]# awk -F: &apos;&#123;printf &quot;%s\n&quot; , $1,$2&#125;&apos; testrootbin[root@test-service ~]# awk -F: &apos;&#123;printf &quot;%s\n%s\n&quot; , $1,$2&#125;&apos; testrootxbinx案列:设置变量指定分隔符[root@test-service ~]# cat testroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologin[root@test-service ~]# awk -v FS=&apos;:&apos; &apos;&#123;printf &quot;第一列: %s\t 第二列: %s\n&quot; , $1,$2&#125;&apos; test第一列: root 第二列: x第一列: bin 第二列: x[root@test-service ~]# awk -v FS=&apos;:&apos; &apos;BEGIN&#123;printf &quot;%-10s\t %s\n&quot; , &quot;username&quot;,&quot;userid&quot;&#125; &#123;printf &quot;%-10s\t %s\n&quot; , $1,$2&#125;&apos; testusername useridroot xbin x awk 分隔符123456789101112131415161718192021222324输入分隔符，英文原文为field separator，此处简称为FS输入分割符，默认是空白字符(即空格)，awk默认以空白字符为分隔符对每一行进行分割。输出分割符，英文原文为output field separator，此处简称为OFSawk将每行分割后，输出在屏幕上的时候，以什么字符作为分隔符，awk默认的输出分割符也是空格。除了使用 -F 选项指定输入分隔符，还能够通过设置内部变量的方式，指定awk的输入分隔符，awk内置变量FS可以用于指定输入分隔符，但是在使用变量时，需要使用-v选项，用于指定对应的变量，比如 -v FS=&apos;#&apos;案列:awk -F: &apos;&#123;print $1,$2&#125;&apos; testawk -v FS=&apos;:&apos; &apos;&#123;print $1,$2&#125;&apos; test总结:而-F，就是options的一种，用于指定输入分隔符-v也是options的一种，用于设置变量的值案列:awk -v FS=&apos;:&apos; -v OFS=&apos;-----&apos; &apos;&#123;print $1,$2&#125;&apos; test #指定输入和输出分隔符，-v 选项设置变量意思在输出的时候，我们想要让两列合并在一起显示，不使用输出分隔符分开显示，该怎么做呢？案列:awk &apos;&#123;print $1$2&#125;&apos; testawk &apos;&#123;print $1 $2&#125;&apos; test awk 变量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889参考网址:https://blog.csdn.net/liang5603/article/details/80855386awk来说&quot;变量&quot;又分为&quot;内置变量&quot; 和 &quot;自定义变量&quot; , &quot;输入分隔符FS&quot;和&quot;输出分隔符OFS&quot;都属于内置变量内置变量就是awk预定义好的、内置在awk内部的变量，而自定义变量就是用户定义的变量。awk常用的内置变量以及其作用如下:FS：输入字段分隔符， 默认为空白字符OFS：输出字段分隔符， 默认为空白字符RS：输入记录分隔符(输入换行符)， 指定输入时的换行符(RS是行输入分隔符)ORS：输出记录分隔符（输出换行符），输出时用指定符号代替换行符(ORS是行输出分隔符)NF：number of Field，当前行的字段的个数(即当前行被分割成了几列)，字段数量NR：行号，当前处理的文本行的行号。FNR：各文件分别计数的行号FILENAME：当前文件名ARGC：命令行参数的个数ARGV：数组，保存的是命令行所给定的各参数内置变量NR：NR是统计文本中行数，NF统计文本中行的列数案列:awk -F: &apos;&#123;print NR,NF&#125;&apos; test$0是打印一整行内容案列:awk -F: &apos;&#123;print NR,$0&#125;&apos; test 细心如你一定注意到了一个细节，就是在打印 $0 , $1 , $2 这些内置变量的时候，都有使用到&quot;$&quot;符号，但是在调用 NR , NF 这些内置变量的时候，就没有使用&quot;$&quot;，如果你有点不习惯，那么可能是因为你已经习惯了使用bash的语法去使用变量，在bash中，我们在引用变量时，都会使用$符进行引用，但是在awk中，只有在引用$0、$1等内置变量的值的时候才会用到&quot;$&quot;,引用其他变量时，不管是内置变量，还是自定义变量，都不使用&quot;$&quot;,而是直接使用变量名内置变量FNRFNR是对多个文件显示行号时使用的，不然用NR对多个文件进行显示行号是按顺序显示的案列:第一列显示是行号，用NR是按顺序显示，FNR是按每个文件单独显示[root@test-service ~]# awk &apos;&#123;print NR,$0&#125;&apos; test test1 #1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologin3 root:x:0:0:root:/root:/bin/bash4 bin:x:1:1:bin:/bin:/sbin/nologin[root@test-service ~]# awk &apos;&#123;print FNR,$0&#125;&apos; test test1 1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologin1 root:x:0:0:root:/root:/bin/bash2 bin:x:1:1:bin:/bin:/sbin/nologin内置变量RS:是输入行分隔符(awk认为,每遇到一个&apos;:&apos;，就换行)案列:[root@test-service ~]# awk -v RS=&apos;:&apos; &apos;&#123;print NR,$0&#125;&apos; test1 #指定&apos;:&apos;为换行符1 root2 xbin3 x内置变量ORS:是输出行分割符(打印到屏幕进行分割)案列:[root@test-service ~]# awk -v ORS=&apos;+++&apos; &apos;&#123;print NR,$0&#125;&apos; test1 1 root:x+++2 bin:x+++内置变量FILENAME:显示文本的文件名案列:第一列是文本的文件名，第二列是每个文本行号，第三列是文本每行内容[root@test-service ~]# awk &apos;&#123;print FILENAME,FNR,$0&#125;&apos; test1 testtest1 1 root:xtest1 2 bin:xtest 1 root:x:0:0:root:/root:/bin/bashtest 2 bin:x:1:1:bin:/bin:/sbin/nologin内置变量ARGC与ARGVARGC内置变量是命令行参数个数ARGV内置变量表示的是一个数组，这个数组中保存的是命令行所给定的参数案列:[root@test-service ~]# awk &apos;BEGIN&#123;print 1111&#125;&apos; test1111[root@test-service ~]# awk &apos;BEGIN&#123;print 1111,ARGV[1]&#125;&apos; test1111 test[root@test-service ~]# awk &apos;BEGIN&#123;print 1111,ARGV[1],ARGV[2]&#125;&apos; test test1 1111 test test1[root@test-service ~]# awk &apos;BEGIN&#123;print 1111,ARGV[0],ARGV[1],ARGV[2]&#125;&apos; test test1 1111 awk test test1[root@test-service ~]# awk &apos;BEGIN&#123;print 1111,ARGV[0],ARGV[1],ARGV[2],ARGC&#125;&apos; test test1 1111 awk test test1 3自定义变量方法一: -v varname=value 变量名区分字符大小写方法二: 在program中直接定义案列:[root@test-service ~]# awk -v myVar=&apos;testVar&apos; &apos;BEGIN&#123;print myVar&#125;&apos;testVar[root@test-service ~]# awk &apos;BEGIN&#123;myvar=&quot;tttt&quot;;print myvar&#125;&apos;tttt[root@test-service ~]# abc=6666666[root@test-service ~]# awk -v myVar=$abc &apos;BEGIN&#123;print myVar&#125;&apos;6666666 正则表达式小节1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#################常用符号#################. 表示任意单个字符。* 表示前面的字符连续出现任意次，包括0次。.* 表示任意长度的任意字符，与通配符中的*的意思相同。\ 表示转义符，当与正则表达式中的符号结合时表示符号本身。[ ]表示匹配指定范围内的任意单个字符。[^ ]表示匹配指定范围外的任意单个字符。 #################单个字符匹配相关#################[[:alpha:]] 表示任意大小写字母。[[:lower:]] 表示任意小写字母。[[:upper:]] 表示任意大写字母。[[:digit:]] 表示0到9之间的任意单个数字（包括0和9）。[[:alnum:]] 表示任意数字或字母。[[:space:]] 表示任意空白字符，包括&quot;空格&quot;、&quot;tab键&quot;等。[[:punct:]] 表示任意标点符号。[^[:alpha:]] 表示单个非字母字符。[^[:lower:]] 表示单个非小写字母字符。[^[:upper:]] 表示单个非大写字母字符。[^[:digit:]] 表示单个非数字字符。[^[:alnum:]] 表示单个非数字非字母字符。[^[:space:]] 表示单个非空白字符。[^[:punct:]] 表示单个非标点符号字符。[0-9]与[[:digit:]]等效。[a-z]与[[:lower:]]等效。[A-Z]与[[:upper:]]等效。[a-zA-Z]与[[:alpha:]]等效。[a-zA-Z0-9]与[[:alnum:]]等效。[^0-9]与[^[:digit:]]等效。[^a-z]与[^[:lower:]]等效。[^A-Z]与[^[:upper:]]等效[^a-zA-Z]与[^[:alpha:]]等效[^a-zA-Z0-9]与[^[:alnum:]]等效#简短格式并非所有正则表达式解析器都可以识别。\d 表示任意单个0到9的数字。\D 表示任意单个非数字字符。\t 表示匹配单个横向制表符（相当于一个tab键）。\s表示匹配单个空白字符，包括&quot;空格&quot;，&quot;tab制表符&quot;等。\S表示匹配单个非空白字符。 #################次数匹配相关#################\? 表示匹配其前面的字符0或1次\+ 表示匹配其前面的字符至少1次，或者连续多次，连续次数上不封顶。\&#123;n\&#125; 表示前面的字符连续出现n次，将会被匹配到。\&#123;x,y\&#125; 表示之前的字符至少连续出现x次，最多连续出现y次，都能被匹配到，换句话说，只要之前的字符连续出现的次数在x与y之间，即可被匹配到。\&#123;,n\&#125; 表示之前的字符连续出现至多n次，最少0次，都会陪匹配到。\&#123;n,\&#125;表示之前的字符连续出现至少n次，才会被匹配到。 #################位置边界匹配相关#################^：表示锚定行首，此字符后面的任意内容必须出现在行首，才能匹配。$：表示锚定行尾，此字符前面的任意内容必须出现在行尾，才能匹配。^$：表示匹配空行，这里所描述的空行表示&quot;回车&quot;，而&quot;空格&quot;或&quot;tab&quot;等都不能算作此处所描述的空行。^abc$：表示abc独占一行时，会被匹配到。\&lt;或者\b ：匹配单词边界，表示锚定词首，其后面的字符必须作为单词首部出现。\&gt;或者\b ：匹配单词边界，表示锚定词尾，其前面的字符必须作为单词尾部出现。\B：匹配非单词边界，与\b正好相反。 #################分组与后向引用#################\( \) 表示分组，我们可以将其中的内容当做一个整体，分组可以嵌套。\(ab\) 表示将ab当做一个整体去处理。\1 表示引用整个表达式中第1个分组中的正则匹配到的结果。\2 表示引用整个表达式中第2个分组中的正则匹配到的结果。 工具下载地址:12345678#对比文件工具https://www.scootersoftware.com/download.php##小乌龟（Tortoisegit）https://tortoisegit.org/download/##图片存放地址https://sm.ms/]]></content>
      <categories>
        <category>正则表达式</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[services]]></title>
    <url>%2F2019%2F06%2F12%2Fservices%2Fservices%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Alpine命令详解]]></title>
    <url>%2F2019%2F06%2F12%2FAlpine%2FAlpine%2F</url>
    <content type="text"><![CDATA[1.apk update$ apk update #更新最新镜像源列表 2.apk search$ apk search #查找所以可用软件包$ apk search -v #查找所以可用软件包及其描述内容$ apk search -v ‘acf*’ #通过软件包名称查找软件包$ apk search -v -d ‘docker’ #通过描述文件查找特定的软件包 3.apk add$ apk add openssh #安装一个软件$ apk add openssh openntp vim #安装多个软件$ apk add –no-cache mysql-client #不使用本地镜像源缓存，相当于先执行update，再执行add 4.apk info$ apk info #列出所有已安装的软件包$ apk info -a zlib #显示完整的软件包信息$ apk info –who-owns /sbin/lbu #显示指定文件属于的包 5.apk upgrade$ apk upgrade #升级所有软件$ apk upgrade openssh #升级指定软件$ apk upgrade openssh openntp vim #升级多个软件$ apk add –upgrade busybox #指定升级部分软件包 6.apk del$ apk del openssh #删除一个软件]]></content>
      <categories>
        <category>Alpine</category>
      </categories>
      <tags>
        <tag>Alpine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis]]></title>
    <url>%2F2019%2F06%2F12%2Fservices%2Fredis%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua]]></title>
    <url>%2F2019%2F06%2F12%2Flua%2Flua%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[go]]></title>
    <url>%2F2019%2F06%2F12%2Fgo%2Fgo%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[自动化运维]]></title>
    <url>%2F2019%2F06%2F12%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[Saltstack 部署安装12345678910111213141516171819202122232425262728293031323334353637383940环境:关闭firewalld，iptables，selinux,设置dns或者hosts解析 python 版本: 2.7 &lt;= python &lt; 3 master和slave设置hosts解析: 192.168.1.117 saltstack-master 192.168.1.118 saltstack-slave####安装saltstack服务端安装:yum -y install epel-releaseyum -y install salt-master salt-minion 服务端配置修改:# vim /etc/salt/minion //在第16行添加，冒号后有一个空格master: saltstack-master客户端安装:yum -y install epel-releaseyum -y install salt-minion客户端配置修改:# vim /etc/salt/minion //在第16行添加，冒号后有一个空格master: saltstack-master客户端和服务端启动服务:service salt-master start #只有服务端安装了该服务service salt-minion start #服务端和客户端都安装此服务配置认证:服务端操作:salt-key -a saltstack-mastersalt-key -a saltstack-slavesalt-key说明：-a ：accept ，-A：accept-all，-d：delete，-D：delete-all。可以使用 salt-key 命令查看到已经签名的客户端。此时我们在客户端的 /etc/salt/pki/minion 目录下面会多出一个minion_master.pub 文件测试验证:示例1： salt &apos;*&apos; test.ping //检测通讯是否正常，也可以指定其中一个 &apos;saltstack-master&apos;示例2: salt &apos;*&apos; cmd.run &apos;df -h&apos; //远程执行命令 Saltstack 错误总结1234561、错误信息 Minion did not return. [Not connected]删除客户端公钥:rm -rf /etc/salt/pki/minion/minion_master.pubservice salt-minion restart #重启client服务 2、错误信息:Failed building wheel for uwsgiyum -y install python-devel（python2.7） Pdsh12345678910111213141516171819202122232425262728##pdsh安装##yum -y install gcc gcc-c++ perl-devel readline-devel bzip2 #安装依赖下载源码包:https://sourceforge.net/projects/pdsh/files/latest/downloadtar -xjvf pdsh-2.26.tar.bz2cd pdsh-2.26 ./configure --prefix=/usr/local/globle/softs/tools/pdsh/2.26/ --with-timeout=60 --with-ssh --with-exec --with-nodeupdown --with-readline --with-machines=/etc/pdsh/machines --with-dshgroups make &amp;&amp; make install参数详解: 选项 解释--prefix 指定安装目录--with-timeout=60 指定pdsh默认执行超时时间--with-ssh 编译ssh模块--with-exec 编译exec模块--with-nodeupdown 编译节点宕机功能--with-readline 编译readline功能--with-rcmd-rank-list 指定默认模式为ssh--with-machines 指定默认主机列表--with-dshgroups 调用组-g选项(默认文件位置:/root/.dsh/group/userhosts or /etc/dsh/group/userhosts)把pdsh安装机器公钥存放到个远端服务器/root/.ssh/authorized_keys ln -s /usr/local/pdsh/bin/pdsh /usr/sbin/pdsh #设置软连接]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes]]></title>
    <url>%2F2019%2F06%2F12%2Fk8s%2Fk8s%2F</url>
    <content type="text"><![CDATA[kubernetes 工作原理12345678910111213141、Master节点包括API Server、Scheduler、Controller manager、etcdAPI Server是整个系统的对外接口，供客户端和其它组件调用，相当于“营业厅”Scheduler负责对集群内部的资源进行调度，相当于“调度室”Controller manager负责管理控制器，相当于“大总管2、Node节点包括Docker、kubelet、kube-proxy、Fluentd、kube-dns（可选）、podPod是Kubernetes最基本的操作单元。一个Pod代表着集群中运行的一个进程，它内部封装了一个或多个紧密相关的容器。除了Pod之外，K8S还有一个Service的概念，一个Service可以看作一组提供相同服务的Pod的对外访问接口Docker 创建容器的Kubelet，主要负责监视指派到它所在Node上的Pod，包括创建、修改、监控、删除等Kube-proxy，主要负责为Pod对象提供代理Fluentd，主要负责日志收集、存储与查询 kubernetes 部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123[镜像地址](https://download.csdn.net/download/qq_33432713/10775173) :https://download.csdn.net/download/qq_33432713/10775173系统环境:CentOS Linux release 7.3.1611 (Core)1、关闭selinux，关闭firewalld，关闭swapsystemctl stop firewalld `&amp;&amp;` systemctl disable firewalldswapoff -a2、配置主机映射和修改主机名hostnamectl set-hostname k8s-master3、yum -y install docker `&amp;&amp;` systemctl start docker `&amp;&amp;` systemctl enable docker 4、 yum -y install kubectl kubelet kubernetes-cni kubeadm (这几个软件需要去google的yum源下载，建议下本地vpnFQ，把软件包下载下来)5、systemctl start kubelet `&amp;&amp;` systemctl enable kubelet6、master端导入需要镜像（详细见软件包）7、kubeadm进行初始化：kubeadm init --kubernetes-version=v1.9.1 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=0.0.0.0 --apiserver-cert-extra-sans=10.2.0.35,127.0.0.1,k8s-master --apiserver-cert-extra-sans #该参数指定自己内网地址和映射在执行过程中，要等几分钟,然后执行以下命令：然后执行如下命令： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config成功以后可以指定一下命令进行查看：kubectl get cskubectl get nodes8、注意：记住该条命令：kubeadm join --token d506ef.63c05fa829529565 10.2.0.37:6443 --discovery-token-ca-cert-hash sha256:4cd1954bf2a1c0904f92328d33bc25471604abd918e019b3c1905289fb8130f2 #在node节点执行该条命令，--token是有有效期的，默认是24小时 9、部署 flannelmkdir -p ~/k8s/wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml #执行会输出一下内容：10、kubectl get pod -n kube-system #注意红框内出现Running状态然后在node节点在node节点部署1、同master节点前五步一样部署2、导入镜像：其实我导入多了，只需要导入一下几个就可以了:gcr.io/google_containers/kube-apiserver-amd64、gcr.io/google_containers/etcd-amd64、quay.io/coreos/flannel、gcr.io/google_containers/etcd-amd643、执行master的第8步，就可以了，然后在master上执行：kubectl get nodes,看到如下图：注意：要想在node节点执行该条命令，需要再node上执行以下命令：sudo cp /etc/kubernetes/admin.conf $HOME/sudo chown $(id -u):$(id -g) $HOME/admin.confexport KUBECONFIG=$HOME/admin.conf不然会出现以下错误:The connection to the server localhost:8080 was refused - did you specify the right host or port?(单独开终端也会出现）++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++最后是版本对应:master:REPOSITORY TAG IMAGE ID CREATED SIZEgcr.io/google_containers/kube-apiserver-amd64 v1.9.1 e313a3e9d78d 7 days ago 210.4 MBgcr.io/google_containers/kube-scheduler-amd64 v1.9.1 677911f7ae8f 7 days ago 62.7 MBgcr.io/google_containers/kube-proxy-amd64 v1.9.1 e470f20528f9 7 days ago 109.1 MBgcr.io/google_containers/kube-controller-manager-amd64 v1.9.1 4978f9a64966 7 days ago 137.8 MBquay.io/coreos/flannel v0.9.1-amd64 2b736d06ca4c 8 weeks ago 51.31 MBgcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.7 db76ee297b85 11 weeks ago 42.03 MBgcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.7 5d049a8c4eec 11 weeks ago 50.27 MBgcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.7 5feec37454f4 11 weeks ago 40.95 MBgcr.io/google_containers/etcd-amd64 3.1.10 1406502a6459 4 months ago 192.7 MBgcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 746.9 kBnode节点对应:REPOSITORY TAG IMAGE ID CREATED SIZEgcr.io/google_containers/kube-apiserver-amd64 v1.9.1 e313a3e9d78d 7 days ago 210.4 MBquay.io/coreos/flannel v0.9.1-amd64 2b736d06ca4c 8 weeks ago 51.31 MBgcr.io/google_containers/etcd-amd64 3.1.10 1406502a6459 4 months ago 192.7 MBgcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 20 months ago 746.9 kB#以下是另一种网络版本对应:REPOSITORY TAG IMAGE ID CREATED SIZEquay.io/calico/node v2.6.2 6763a667e3ba 12 weeks ago 281.6 MBquay.io/calico/cni v1.11.0 c3482541970f 3 months ago 70.88 MB错误信息总结:1、错误:Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of &quot;crypto/rsa: verification error&quot; while trying to verify candidate authority certificate &quot;kubernetes&quot;)解决方案：设置环境变量：sudo cp /etc/kubernetes/admin.conf $HOME/sudo chown $(id -u):$(id -g) $HOME/admin.confexport $KUBECONFIG=$HOME/.kube/admin.conf2、错误：[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1解决方案：cat /etc/sysctl.conf net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 13、获取登录token[root@k8s-master-cs-new ~]# kubectl -n kube-system get secret | grep kubernetes-dashboard[root@k8s-master-cs-new ~]# kubectl describe -n kube-system secret/kubernetes-dashboard-token-prn6c]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell]]></title>
    <url>%2F2019%2F06%2F12%2Fshell%2Fshell%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python]]></title>
    <url>%2F2019%2F06%2F12%2Fpython%2Fpython%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[docker]]></title>
    <url>%2F2019%2F06%2F12%2Fdocker%2Fdocker%2F</url>
    <content type="text"><![CDATA[dockerdocker常识积累123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990docker CE社区版官方免费支持(7个月)docker EE企业版官方免费支持(24个月)国内支持仓库云服务商: 时速云镜像仓库、网易云镜像服务、DaoCloud 镜像市场、阿里云镜像###centos 安装docker-ce$ sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine安装依赖包:sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2添加yum源:sudo yum-config-manager \ --add-repo \ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo官网源:# $ sudo yum-config-manager \# --add-repo \# https://download.docker.com/linux/centos/docker-ce.repo如果需要测试版本的 Docker CE 请使用以下命令：$ sudo yum-config-manager --enable docker-ce-test如果需要每日构建版本的 Docker CE 请使用以下命令：$ sudo yum-config-manager --enable docker-ce-nightly更新 yum 软件源缓存，并安装 docker-ce$ sudo yum makecache fast$ sudo yum install docker-ce使用脚本自动安装$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun启动 Docker CE$ sudo systemctl enable docker$ sudo systemctl start docker添加内核参数如果在 CentOS 使用 Docker CE 看到下面的这些警告信息：WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled请添加内核配置参数以启用这些功能。$ sudo tee -a /etc/sysctl.conf &lt;&lt;-EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF然后重新加载 sysctl.conf 即可$ sudo sysctl -p查看镜像大小docker system df #查看镜像、容器、数据卷所占用的空间docker images 等于 docker image ls #查看镜像实际占用磁盘空间docker image ls -f dangling=true #显示虚悬镜像(虚悬镜像:是指没有仓库名和标签的镜像)docker image prune #删除虚悬镜像# docker image ls -f before=crond_new:1.0.1 #查看crond_new:1.0.1之前建立镜像# docker image ls -f since=crond_dev:1.0.0 #查看crond_dev:1.0.0之后建立镜像# docker image ls -q #只列出镜像ID# docker image ls --format &quot;&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;&quot; #只列出镜像ID和仓库名# docker image ls --format &quot;table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Repository&#125;&#125;\t&#123;&#123;.Tag&#125;&#125;&quot; #指定间隔符号# docker image ls --digests #获取精确镜像摘要 # docker rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 #根据镜像摘要进行删除# docker image rm $(docker image ls -q redis) #删除redis实列 docker volume1234567891011121314151617181920212223docker volume lsdocker volume inspect my-voldocker run -d -P --name web --mount source=my-vol,target=/webapp training/webapp python app.py #挂载实列docker inspect web #查看逻辑卷信息docker volume rm my-vol #删除逻辑卷docker volume prune #删除无主逻辑卷docker run -itd --name test_local --restart=always --mount type=bind,source=/opt/app,target=/kuaibao/www alpine /bin/sh #挂载本地目录至容器中，和-v选项区别是:本地目录不存在时会报错，而-v则会自己创建docker run -itd --name test --restart=always --mount source=my-vol,target=/kuaibao/www alpine /bin/sh #挂载本地创建的volume挂载至容器中Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读。docker run -itd --name test_read --restart=always --mount type=bind,source=/opt/app,target=/kuaibao/www,readonly alpine /bin/sh #只读模式,如下测试[root@k8s-slave ~]# docker exec -it test_read touch /kuaibao/www/1.txttouch: /kuaibao/www/1.txt: Read-only file systemdocker run -itd --name test_file --restart=always --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history alpine /bin/sh #挂载文件至容器中 docker 选项12345678910EXPOSE 记录服务可用端口，但是并不创建喝宿主机之间的映射--export 运行时暴露端口，但是并不创建喝宿主机之间的映射-p 创建端口映射规则，比如 -p ip:hostPort:containerPort| ip::containerPort | hostPort:containerPort | containerPort 必须指定containerPort,如果没有指定hostPort，Docker 会自动分配端口 -P 将Dockerfile里暴露的所有容器端口映射到动态分配的宿主机端口上--link 在消费和服务容器之间创建链接，比如 --link name:alias 这会创建一系列环境变量，并在消费者容器的/etc/hosts文件里添加入口项 必须暴露或发布端口 docker log123456789101112131415161718192021docker logs [OPTIONS] CONTAINER Options: --details 显示更多的信息 -f, --follow 跟踪实时日志 --since string 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） --tail string 从日志末尾显示多少行日志， 默认是all -t, --timestamps 显示时间戳 --until string 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟）案列:#查看指定时间后的日志，只显示最后100行：docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 CONTAINER_ID#查看最近30分钟的日志docker logs --since 30m CONTAINER_ID#查看某时间之后的日志：docker logs -t --since=&quot;2018-02-08T13:23:37&quot; CONTAINER_ID#查看某时间段日志docker logs -t --since=&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; CONTAINER_ID docker-compose123456789101112131415161718192021222324252627282930313233343536373839404142434445docker-compose create 创建所有的服务docker-compose start 启动被停止或未启动的服务docker-compose up 创建所有服务并且启动服务，即同时执行了create和start命令docker-compose stop 停止所有服务docker-compose kill 强行停止所有服务docker-compose rm 删除停止的服务docker-compose restart 重启所有服务docker-compose down 停止、删除所有的服务以及网络、镜像docker-compose up -d nginx #构建建启动nignx容器docker-compose exec nginx bash #登录到nginx容器中docker-compose down #删除所有nginx容器,镜像docker-compose ps #显示所有容器docker-compose restart ngin #重新启动nginx容器docker-compose run --no-deps --rm php-fpm php -v #在php-fpm中不启动关联容器，并容器执行php -v 执行完成后删除容器docker-compose build nginx #构建镜像docker-compose build --no-cache nginx #不带缓存的构建docker-compose logs nginx #查看nginx的日志docker-compose logs -f nginx #验证（docker-compose.yml）文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息docker-compose pause nginx #暂停nignx容器docker-compose unpause nginx #恢复ningx容器docker-compose rm nginx #删除容器（删除前必须关闭容器）docker-compose stop nginx #停止nignx容器docker-compose start nginx #启动nignx容器 说明:以下是制作php的crond计划任务镜像123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108命令:docker run -d --name crond -v /www/:/www/ web:1.0.0FROM alpine:edgeMAINTAINER Cuibobo &lt;cuibobo@kuaidihelp.com&gt;ENV LANG=C.UTF-8ENV PHP_FPM_USER=&quot;www&quot; ENV PHP_FPM_GROUP=&quot;www&quot; ENV PHP_FPM_LISTEN_MODE=&quot;0660&quot;ENV PHP_MEMORY_LIMIT=&quot;512M&quot;ENV PHP_MAX_UPLOAD=&quot;50M&quot;ENV PHP_MAX_FILE_UPLOAD=&quot;200&quot;ENV PHP_MAX_POST=&quot;100M&quot;ENV PHP_DISPLAY_ERRORS=&quot;On&quot;ENV PHP_DISPLAY_STARTUP_ERRORS=&quot;On&quot;ENV PHP_ERROR_REPORTING=&quot;E_COMPILE_ERROR\|E_RECOVERABLE_ERROR\|E_ERROR\|E_CORE_ERROR&quot;ENV PHP_CGI_FIX_PATHINFO=0ENV TIMEZONE=&quot;Asia/Shanghai&quot;COPY ./service.sh /root/COPY ./ErrorLogWriterDev.phar /root/COPY ./rsyslog.conf /opt/RUN apk update &amp;&amp; \ apk add --no-cache tzdata &amp;&amp; \ apk add --no-cache php7-fpm \ php7 \ php7-mcrypt \ php7-soap \ php7-openssl \ php7-gmp \ php7-pdo_odbc \ php7-json \ php7-dom \ php7-pdo \ php7-zip \ php7-mysqli \ php7-phar \ php7-sqlite3 \ php7-apcu \ php7-pdo_pgsql \ php7-bcmath \ php7-gd \ php7-odbc \ php7-pdo_mysql \ php7-pdo_sqlite \ php7-gettext \ php7-xmlreader \ php7-xmlrpc \ php7-bz2 \ php7-sockets \ php7-xmlwriter \ php7-xsl \ php7-tokenizer \ php7-ftp \ php7-posix \ php7-fileinfo \ php7-shmop \ php7-mbstring \ php7-iconv \ php7-pdo_dblib \ php7-curl \ php7-session \ php7-ctype \ php7-simplexml \ php7-redis &amp;&amp; \ sed -i &quot;s|;listen.owner\s*=\s*nobody|listen.owner = $&#123;PHP_FPM_USER&#125;|g&quot; /etc/php7/php-fpm.d/www.conf &amp;&amp; \sed -i -e &quot;s/;daemonize\s*=\s*yes/daemonize = no/g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i -e &quot;s/;slowlog/slowlog/g&quot; /etc/php7/php-fpm.d/www.conf &amp;&amp; \sed -i &quot;s|;listen.group\s*=\s*nobody|listen.group = $&#123;PHP_FPM_GROUP&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|;listen.mode\s*=\s*0660|listen.mode = $&#123;PHP_FPM_LISTEN_MODE&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|user\s*=\s*nobody|user = $&#123;PHP_FPM_USER&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|group\s*=\s*nobody|group = $&#123;PHP_FPM_GROUP&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|;log_level\s*=\s*notice|log_level = notice|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|display_errors\s*=\s*Off|display_errors = $&#123;PHP_DISPLAY_ERRORS&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|display_startup_errors\s*=\s*Off|display_startup_errors = $&#123;PHP_DISPLAY_STARTUP_ERRORS&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|error_reporting\s*=\s*E_ALL &amp; ~E_DEPRECATED &amp; ~E_STRICT|error_reporting = $&#123;PHP_ERROR_REPORTING&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*memory_limit =.*|memory_limit = $&#123;PHP_MEMORY_LIMIT&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*upload_max_filesize =.*|upload_max_filesize = $&#123;PHP_MAX_UPLOAD&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*max_file_uploads =.*|max_file_uploads = $&#123;PHP_MAX_FILE_UPLOAD&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*post_max_size =.*|post_max_size = $&#123;PHP_MAX_POST&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*cgi.fix_pathinfo=.*|cgi.fix_pathinfo= $&#123;PHP_CGI_FIX_PATHINFO&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \cp /usr/share/zoneinfo/$&#123;TIMEZONE&#125; /etc/localtime &amp;&amp; \echo &quot;$&#123;TIMEZONE&#125;&quot; &gt; /etc/timezone &amp;&amp; \sed -i &quot;s|;*date.timezone =.*|date.timezone = $&#123;TIMEZONE&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \ mkdir /www &amp;&amp; \ apk del tzdata curl &amp;&amp; \ adduser -D -g &apos;www&apos; www &amp;&amp; \ chown -R www:www /www &amp;&amp; \ apk add rsyslog logrotate &amp;&amp; \ rm -f /etc/rsyslog.conf &amp;&amp; \ mv /opt/rsyslog.conf /etc/ &amp;&amp; \ apk add --no-cache --repository http://dl-4.alpinelinux.org/alpine/edge/testing gnu-libiconv &amp;&amp; \ rm -rf /var/cache/apk/*ENV LD_PRELOAD /usr/lib/preloadable_libiconv.so phpWORKDIR /wwwVOLUME [&quot;/www&quot;]EXPOSE 80CMD [&quot;/root/service.sh&quot;]Alpine操作系统源码安装swoole需要依赖apk add gcc g++ make php7-dev php7-pear php7-dev #phpizephp7-pear #pecl pecl install swoole-4.2.8.tgz #选择mysqld和socket php+openresty(alpine)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209server.sh 可以根据自己情况编写，但是要以php7-fpm结尾打包镜像docker built -t web:1.0.0 -f Dockerfile . --no-cachedocker 运行实例docker run -d --privileged=true --name test --restart=always -p 80:80 -v /data/:/www/ web:1.0.0FROM alpine:edgeMAINTAINER Cuibobo &lt;cuibobo@kuaidihelp.com&gt;ENV PHP_FPM_USER=&quot;www&quot; ENV PHP_FPM_GROUP=&quot;www&quot; ENV PHP_FPM_LISTEN_MODE=&quot;0660&quot;ENV PHP_MEMORY_LIMIT=&quot;512M&quot;ENV PHP_MAX_UPLOAD=&quot;50M&quot;ENV PHP_MAX_FILE_UPLOAD=&quot;200&quot;ENV PHP_MAX_POST=&quot;100M&quot;ENV PHP_DISPLAY_ERRORS=&quot;On&quot;ENV PHP_DISPLAY_STARTUP_ERRORS=&quot;On&quot;ENV PHP_ERROR_REPORTING=&quot;E_COMPILE_ERROR\|E_RECOVERABLE_ERROR\|E_ERROR\|E_CORE_ERROR&quot;ENV PHP_CGI_FIX_PATHINFO=0ENV TIMEZONE=&quot;Asia/Shanghai&quot;ARG RESTY_VERSION=&quot;1.13.6.2&quot;ARG RESTY_OPENSSL_VERSION=&quot;1.0.2p&quot;ARG RESTY_PCRE_VERSION=&quot;8.42&quot;ARG RESTY_J=&quot;3&quot;ARG RESTY_CONFIG_OPTIONS=&quot;\ --with-file-aio \ --with-http_addition_module \ --with-http_auth_request_module \ --with-http_dav_module \ --with-http_flv_module \ --with-http_geoip_module=dynamic \ --with-http_gunzip_module \ --with-http_gzip_static_module \ --with-http_image_filter_module=dynamic \ --with-http_mp4_module \ --with-http_random_index_module \ --with-http_realip_module \ --with-http_secure_link_module \ --with-http_slice_module \ --with-http_ssl_module \ --with-http_stub_status_module \ --with-http_sub_module \ --with-http_v2_module \ --with-http_xslt_module=dynamic \ --with-ipv6 \ --with-mail \ --with-mail_ssl_module \ --with-md5-asm \ --with-pcre-jit \ --with-sha1-asm \ --with-stream \ --add-dynamic-module=/opt/ngx_http_substitutions_filter_module-master \ --with-stream_ssl_module \ --with-pcre=/tmp/pcre-$&#123;RESTY_PCRE_VERSION&#125; \ --with-openssl=/tmp/openssl-$&#123;RESTY_OPENSSL_VERSION&#125; \ --with-threads \ &quot;ARG RESTY_CONFIG_OPTIONS_MORE=&quot;&quot;ARG RESTY_ADD_PACKAGE_BUILDDEPS=&quot;&quot;ARG RESTY_ADD_PACKAGE_RUNDEPS=&quot;&quot;ARG RESTY_EVAL_PRE_CONFIGURE=&quot;&quot;ARG RESTY_EVAL_POST_MAKE=&quot;&quot;LABEL resty_version=&quot;$&#123;RESTY_VERSION&#125;&quot;LABEL resty_openssl_version=&quot;$&#123;RESTY_OPENSSL_VERSION&#125;&quot;LABEL resty_pcre_version=&quot;$&#123;RESTY_PCRE_VERSION&#125;&quot;LABEL resty_config_options=&quot;$&#123;RESTY_CONFIG_OPTIONS&#125;&quot;LABEL resty_config_options_more=&quot;$&#123;RESTY_CONFIG_OPTIONS_MORE&#125;&quot;LABEL resty_add_package_builddeps=&quot;$&#123;RESTY_ADD_PACKAGE_BUILDDEPS&#125;&quot;LABEL resty_add_package_rundeps=&quot;$&#123;RESTY_ADD_PACKAGE_RUNDEPS&#125;&quot;LABEL resty_eval_pre_configure=&quot;$&#123;RESTY_EVAL_PRE_CONFIGURE&#125;&quot;LABEL resty_eval_post_make=&quot;$&#123;RESTY_EVAL_POST_MAKE&#125;&quot; COPY ./ngx_http_substitutions_filter_module-master /opt/ngx_http_substitutions_filter_module-masterCOPY ./echo-nginx-module /opt/echo-nginx-moduleCOPY ./service.sh /root/COPY ./old /opt/oldCOPY ./host /opt/hostCOPY ./rsyslog.conf /opt/rsyslog.confRUN apk update &amp;&amp; \ apk add --no-cache tzdata &amp;&amp; \ apk add --no-cache php7-fpm \ php7 \ php7-mcrypt \ php7-soap \ php7-openssl \ php7-gmp \ php7-pdo_odbc \ php7-json \ php7-dom \ php7-pdo \ php7-zip \ php7-mysqli \ php7-sqlite3 \ php7-apcu \ php7-pdo_pgsql \ php7-bcmath \ php7-gd \ php7-odbc \ php7-pdo_mysql \ php7-pdo_sqlite \ php7-gettext \ php7-xmlreader \ php7-xmlrpc \ php7-bz2 \ php7-sockets \ php7-xmlwriter \ php7-xsl \ php7-tokenizer \ php7-ftp \ php7-posix \ php7-fileinfo \ php7-shmop \ php7-mbstring \ php7-iconv \ php7-pdo_dblib \ php7-curl \ php7-session \ php7-ctype \ php7-redis &amp;&amp; \ sed -i &quot;s|;listen.owner\s*=\s*nobody|listen.owner = $&#123;PHP_FPM_USER&#125;|g&quot; /etc/php7/php-fpm.d/www.conf &amp;&amp; \sed -i -e &quot;s/;daemonize\s*=\s*yes/daemonize = no/g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i -e &quot;s/;slowlog/slowlog/g&quot; /etc/php7/php-fpm.d/www.conf &amp;&amp; \sed -i &quot;s|;listen.group\s*=\s*nobody|listen.group = $&#123;PHP_FPM_GROUP&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|;listen.mode\s*=\s*0660|listen.mode = $&#123;PHP_FPM_LISTEN_MODE&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|user\s*=\s*nobody|user = $&#123;PHP_FPM_USER&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|group\s*=\s*nobody|group = $&#123;PHP_FPM_GROUP&#125;|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|;log_level\s*=\s*notice|log_level = notice|g&quot; /etc/php7/php-fpm.conf &amp;&amp; \sed -i &quot;s|display_errors\s*=\s*Off|display_errors = $&#123;PHP_DISPLAY_ERRORS&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|display_startup_errors\s*=\s*Off|display_startup_errors = $&#123;PHP_DISPLAY_STARTUP_ERRORS&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|error_reporting\s*=\s*E_ALL &amp; ~E_DEPRECATED &amp; ~E_STRICT|error_reporting = $&#123;PHP_ERROR_REPORTING&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*memory_limit =.*|memory_limit = $&#123;PHP_MEMORY_LIMIT&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*upload_max_filesize =.*|upload_max_filesize = $&#123;PHP_MAX_UPLOAD&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*max_file_uploads =.*|max_file_uploads = $&#123;PHP_MAX_FILE_UPLOAD&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*post_max_size =.*|post_max_size = $&#123;PHP_MAX_POST&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \sed -i &quot;s|;*cgi.fix_pathinfo=.*|cgi.fix_pathinfo= $&#123;PHP_CGI_FIX_PATHINFO&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \cp /usr/share/zoneinfo/$&#123;TIMEZONE&#125; /etc/localtime &amp;&amp; \echo &quot;$&#123;TIMEZONE&#125;&quot; &gt; /etc/timezone &amp;&amp; \sed -i &quot;s|;*date.timezone =.*|date.timezone = $&#123;TIMEZONE&#125;|i&quot; /etc/php7/php.ini &amp;&amp; \ apk add --no-cache --virtual .build-deps \ build-base \ curl \ gd-dev \ geoip-dev \ libxslt-dev \ linux-headers \ make \ perl-dev \ readline-dev \ zlib-dev \ $&#123;RESTY_ADD_PACKAGE_BUILDDEPS&#125; \ &amp;&amp; apk add --no-cache \ gd \ geoip \ libgcc \ libxslt \ zlib \ $&#123;RESTY_ADD_PACKAGE_RUNDEPS&#125; \ &amp;&amp; cd /tmp \ &amp;&amp; if [ -n &quot;$&#123;RESTY_EVAL_PRE_CONFIGURE&#125;&quot; ]; then eval $(echo $&#123;RESTY_EVAL_PRE_CONFIGURE&#125;); fi \ &amp;&amp; curl -fSL https://www.openssl.org/source/openssl-$&#123;RESTY_OPENSSL_VERSION&#125;.tar.gz -o openssl-$&#123;RESTY_OPENSSL_VERSION&#125;.tar.gz \ &amp;&amp; tar xzf openssl-$&#123;RESTY_OPENSSL_VERSION&#125;.tar.gz \ &amp;&amp; curl -fSL https://ftp.pcre.org/pub/pcre/pcre-$&#123;RESTY_PCRE_VERSION&#125;.tar.gz -o pcre-$&#123;RESTY_PCRE_VERSION&#125;.tar.gz \ &amp;&amp; tar xzf pcre-$&#123;RESTY_PCRE_VERSION&#125;.tar.gz \ &amp;&amp; curl -fSL https://openresty.org/download/openresty-$&#123;RESTY_VERSION&#125;.tar.gz -o openresty-$&#123;RESTY_VERSION&#125;.tar.gz \ &amp;&amp; tar xzf openresty-$&#123;RESTY_VERSION&#125;.tar.gz \ &amp;&amp; cd /tmp/openresty-$&#123;RESTY_VERSION&#125; \ &amp;&amp; ./configure -j$&#123;RESTY_J&#125; $&#123;_RESTY_CONFIG_DEPS&#125; $&#123;RESTY_CONFIG_OPTIONS&#125; $&#123;RESTY_CONFIG_OPTIONS_MORE&#125; \ &amp;&amp; make -j$&#123;RESTY_J&#125; \ &amp;&amp; make -j$&#123;RESTY_J&#125; install \ &amp;&amp; cd /tmp \ &amp;&amp; if [ -n &quot;$&#123;RESTY_EVAL_POST_MAKE&#125;&quot; ]; then eval $(echo $&#123;RESTY_EVAL_POST_MAKE&#125;); fi \ &amp;&amp; rm -rf \ openssl-$&#123;RESTY_OPENSSL_VERSION&#125; \ openssl-$&#123;RESTY_OPENSSL_VERSION&#125;.tar.gz \ openresty-$&#123;RESTY_VERSION&#125;.tar.gz openresty-$&#123;RESTY_VERSION&#125; \ pcre-$&#123;RESTY_PCRE_VERSION&#125;.tar.gz pcre-$&#123;RESTY_PCRE_VERSION&#125; \ &amp;&amp; apk del .build-deps \ &amp;&amp; rm -rf /opt/ngx_http_substitutions_filter_module-master \ &amp;&amp; rm -rf /opt/echo-nginx-module \ &amp;&amp; ln -sf /dev/stdout /usr/local/openresty/nginx/logs/access.log \ &amp;&amp; ln -sf /dev/stderr /usr/local/openresty/nginx/logs/error.log &amp;&amp; \ mkdir /www &amp;&amp; \ apk del tzdata curl &amp;&amp; \ adduser -D -g &apos;www&apos; www &amp;&amp; \ chown -R www:www /www &amp;&amp; \ mkdir /run/nginx/ &amp;&amp; \ mv /opt/old/* /usr/local/openresty/nginx/conf/ &amp;&amp; \ apk add rsyslog &amp;&amp; \ apk add --no-cache --repository http://dl-4.alpinelinux.org/alpine/edge/testing gnu-libiconv &amp;&amp; \ rm -rf /var/cache/apk/*# Add additional binaries into PATH for convenienceENV LD_PRELOAD /usr/lib/preloadable_libiconv.so phpENV PATH=$PATH:/usr/local/openresty/luajit/bin:/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin# Copy nginx configuration filesCOPY nginx.conf /usr/local/openresty/nginx/conf/nginx.confCOPY vhosts /usr/local/openresty/nginx/conf/vhosts #COPY key /usr/local/openresty/nginx/conf/keyWORKDIR /wwwVOLUME [&quot;/www&quot;]EXPOSE 80CMD [&quot;/root/service.sh&quot;]]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
        <tag>docker-volume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软中断]]></title>
    <url>%2F2019%2F06%2F11%2Flinux%E6%93%8D%E4%BD%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F%E8%BD%AF%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[软中断123456789101112131415161718192021222324252627top -H -p XX 1 / pidstat -wut -p XX 1 #那个线程占用CPUperf report -g -p XX 是否可以定位到具体的系统调用函数.中断:系统用来响应硬件设备请求的一种机制，会打断进程的正常调度和执行，通过调用内核中的中断处理程序来响应设备的请求(中断是一种异步的事件处理机制，用来提高系统的并发处理能力。中断事件发生，会触发执行中断处理程序，而中断处理程序被分为上半部和下半部这两个部分)上半部对应硬中断，用来快速处理中断下半部对应软中断，用来异步处理上半部未完成的工作1.中断是一种异步的事件处理机制，能提高系统的并发处理能力2.为了减少对正常进程运行进行影响，中断处理程序需要尽快运行。3.中断分为上下两个部分(1)上部分用来快速处理中断，在中断禁止模式下，主要处理跟硬件紧密相关的或时间敏感的工作(2)下部分用来延迟处理上半部分未完成的工作，通常以内核线程的方式运行。小结:上半部分直接处理硬件请求，即硬中断，特点是快速执行下部分由内核触发，即软中断，特点是延迟执行软中断除了上面的下部分，还包括一些内核自定义的事件，如:内核调度 RCU锁 网络收发 定时等软中断内核线程的名字:ksoftirq/cpu编号4.proc文件系统是一种内核空间和用户空间进行通信的机制，可以同时用来查看内核的数据结构又能用了动态修改内核的配置，如:/proc/softirqs 提供软中断的运行情况/proc/interrupts 提供硬中断的运行情况 进程状态12345678910111213141516171819202122232425262728293031323334当iowait升高时，进程很可能因为得不到硬件的响应，而长时间处于不可中断状态。从ps或者top命令的输出中，你可以发现它们都处于D状态，也就是不可中断状态(Uninterruptible Sleep)。进程状态有哪几种:R 是Running 或 Runnable 的缩写，表示进程CPU的就绪队列中，正在运行或者正在等待运行D 是Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep）,一般表示进程正在跟硬件交互，并且交互过程中不允许被其他进程或中断打断Z 是Zombie的缩写，也就是可中断状态的睡眠，表示进程因为等待某个事件而被系统挂起，当进程等待的时间发生时，它会被唤醒并进入R状态I 是idle的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上，前面说了，硬件交互导致的不可中断进程D表示，但对某些内核线程会导致平均负载升高，I状态的进程却不会。T或者t 也就是Stopped和Traced的缩写，表示进程处于暂停或者跟踪状态向一个进程发送SIGSTOP信号，它就会因为响应这个信号变成暂停状态(Stopped);再向它发送SIGCONF信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用fg命令，恢复到前台运行）X 也是Dead的缩写，表示进程已经消亡，所以你不会再top或者ps命令中看到它总结:不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统I/O性能问题僵尸进程表示进程已经退出，但它的父进程还没有回收子进程占用的资源。短暂的僵尸状态我们通常不必理会但进程长时间处于僵尸状态，就应该注意了，可能有应用程序没有正常处理子进程的退出总结:分析系统等待I/O的CPU使用率(也就是iowait%)升高的情况iowait高并不一定代码I/O有性能瓶颈。当然系统中只有I/O类型的进程在运行时，iowait也会很高但是实际上，磁盘的读写远没有达到性能瓶颈的程度因此，碰到iowait升高时，需要先用dstat、pidstat等工具，确认是不是磁盘I/O问题，然后找是那些进程导致了I/O升高等待I/O的进程一般是不可中断状态，所以用ps命令找到的D状态（即不可中断状态）的进程，多为可以进程当一个进程执行到最后成僵尸进程，就不能用strace，因为当前进程已经不存在了用ps查看该进程是D状态是可以用strace进行追踪，否则用另外一种方法:perf record -g(执行15s)停止，用perf report 进行查看分析 某个应用cpu使用率居然达到100%，该怎么处理12345678910111213141516171819202122232425262728293031323334353637383940411、linux并发(任务并行)的实质：linux作为一个多任务操作系统，将每个CPU的时间划分为很短站的时间片，再通过调度器轮流分配给各个任务使用，再通过调度器轮流分配给各个任务使用2、CPU的维护，通过实现定义的节拍率(内核用赫兹HZ标示)，触发时间判断(全局变量jiffes)记录。3、节拍率的内核态运行，属于内核空间节拍率：用户空间节拍率（USER_HZ）是一个固定值4、/proc/stat 提供的就是系统的CPU核任务统计系统信息: /proc/[pid]/stat展示进程的CPU核任务统计信息5、CPU的使用率=&#123;1-(idle_time/total_cpu_time)&#125;/sample_ti6、性能分析工具给出的都是间隔一段时间的平均CPU使用率，所以要注意间隔的设置。top默认为3s，ps使用的是进程运行时间7、top、vmstat、mpstat等命令关于CPU性能相关指标的含义8、pidstat命令指标的含义9、perf以前用到的一堆[n]trace分析工具，perf的直观易用，这是今天最大的收获，作为dba对数据库的分析很有用的perf top、perf record、perf report对进程进行跟踪分析其调用perf top -g -p &lt;mysqlpid&gt;10、今天用测试工具:ab (apache-utils centos安装包)如果碰到不好解释的CPU问题时，比如现象：通过top观察CPU使用率很高，但是看下面的进程的CPU使用率好像很正常，通过pidstat命令查看cpu也很正常。但通过top查看task数量不正常，处于R状态的进程是可疑点。首先要想到可能是短时间的应用导致的问题，如下面的两个：（1）应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过top等工具发现不了（2）应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用很多CPU资源对于这类进程就需要 pstree 或execsnoop命令查找父进程，再从父进程的应用入手，找原因。我实战的问题：（1）centos的系统，发现通过 yum install pstress命令或其他命令，总是说没有匹配的软件包，这个很头疼①pstress装不上可以尝试 yum install psmisc②execsnoop这个命令我没有装上，想请教下老师如何解决这种yum install命令报没有匹配包的情况（2）然后就是通过perf命令只能看到十六进制符号，看不到具体函数名的问题，这个可以使用上篇文章中我的留言的方法，我在copy一份，供大家参考分析：当没有看到函数名，只看到十六进制时，说明perf无法找到待分析进程所依赖的库。解决办法：在容器外面把分析记录保存，到容器里面查看结果操作：（1）在centos系统上运行 perf record -g ，执行一会儿按ctrl+c停止（2）把生成的perf.data（通常文件生成在命令执行的当前目录下，当然可以通过find | grep perf.data或 find / -name perf.data查看路径）文件拷贝到容器里面分析： CPU上下文切换CPU上下文切换(上篇)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485cpu上下文切换分为:进程上下文切换，线程上线文切换和中断上下文切换1、进程上线文切换 Linux安装特权等级，把进程的运行空间分为内核空间和用户空间 内核空间具有最高权限，可以直接访问所有资源 用户空间只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中才能访问这些特权资源 换个角度看，也就是说，进程既可以在用户空间运行，也可以在内核空间运行。进程在用户空间运行时，被称为进程的用户态， 而陷入内核空间的时候，被称为进程的内核态 从用户态和内核态的转变，需要通过系统调用来完成，比如：当我们查看文件内容时，就需要多次系统调用来完成，首先调用 open()打开文件，然后调用read()读取文件内容，并调用write()将内容写到标准输出，最后调用close()关闭文件 CPU寄存器里原来用户态的指令的位置，需要先保存起来，接着，为了执行内核态代码，CPU寄存器需要更新为内核态指令的新位置 ，最后才跳转到内核态运行内核任务 而系统调用结束后，CPU寄存器需要恢复原来保存的用户态，然后再切到用户空间，继续运行进程，所以，一次系统调用的过程，其实时发生了两次cpu上线文切换，不过需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程，这跟我们通常所说的进程上线文切换时不一样的 (1) 进程上线文切换，是指一个进程切换到另一个进程运行 (2) 而系统调用过程中一直是同一个进程在运行 所以，系统调用过程通常为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU的上线文切换时无法避免的 进程上下文切换跟系统调用有什么区别呢? 首先，进程是由内核来管理和调度的，进程的切换只发生在内核。所以，进程的上下问不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态 因此，进程的上下问切换就比系统调用时多了一步:在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一个进程的内核后。还需要新进程的虚拟内存和用户栈 根据Tsuna测试报告，每次上下文切换都需要几十纳秒到数微妙的CPU的时间.这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致CPU将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间，这也正是上一节中我们所讲的，导致平均负载升高的一个重要因素另外 Linux是通过TLB(Translation Lookaside) 来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB也需要刷新，内存的访问也会随之变慢，特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程进程在什么时候才会被调度到CPU上运行呢？最容易想到的一个时机，就是进程执行完终止了，它之前使用的CPU会释放出来，这个时候再从就绪队列，拿一个新的进程过来运行，其实还有很多其他场景，也会触发进程调度，如下: (1) 为了保证所有进程可以得到公平调度，CPU时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样当某个进程的时间片耗尽了，就会被系统挂起，切到其它正在等待CPU的进程运行 (2) 进程在系统资源不足(比如内存不足)时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 (3) 当进程通过睡眠函数sleep这样的方法将自己主动挂起时，自然也会重新调度 (4) 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程运行 最后一个，发生硬件中断时，CPU上的进程会被中断挂起，转而执行内核中的中断服务程序2、线程上线文切换 线程和进程最大区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以对于线程和进程，我们可以这样理解: (1) 当进程只有一个线程时，可以认为进程就等于线程 (2) 当进程拥有多个线程时，这些线程会共享3、中断上下文切换 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以即便中断过程打断一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必须的状态，包括CPU寄存器、内核堆栈和硬件中断参数等。 对同一个CPU来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。 另外，跟进程上下文切换一样，中断上下文切换也需要消耗CPU，切换次数过多也会消耗大量CPU，甚至严重降低系统的整体性能，所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题场景:cpu上下文切换，是保证Linux系统正常工作的核心功能之一，一般情况下不需要我们特别关注但过多的上下文切换，会把CPU时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能答复下降总结:1、多任务竞争CPU，CPU变换任务时进行cpu上下文切换（context switch）。CPU执行任务4中方式:进程、线程、或者硬件通过触发信号导致cpu中断的调用2、当切换任务的时候，需要记得任务当前的状态和获取下一任务信息和地址(指针)，这就是上下文的内容，因此，上下文是指某一时间CPU寄存器(CPU register)和程序计数器(PC)的内容，广义上还包括内存中进程的虚拟地址映射信息3、上下文切换的过程 (1) 记录当前任务的上下文(即寄存器和计算器等所有的状态) (2) 找到新任务的上下文并加载 (3) 切换到新任务的程序计算器位置，恢复期任务4、根据任务的执行形式，相互的下上文切换，有进程上下文切换、线程上下文切换以及中断上下文切换三类5、进程和线程区别：进程是资源分配合执行的基本单位；线程是任务调度和运行的基本单位。线程没有资源，进程给指针提供虚拟内存、栈和变量等共享资源，而线程可以共享进程的资源6、进程上线文切换:是指从一个进程切换到另一个进程。 (1) 进程运行态为内核运行态和进程运行态，内核空间态资源包括内核的堆栈、寄存器等；用户空间态资源包括虚拟内存、栈、变量、正文和数据等 (2) 系统调用(软中断)在内核态完成的，需要进行2次CPU上下文切换(用户空间-&gt;内核空间-&gt;用户空间)，不涉及用户资源，也不会切换进程 (3) 进程是由内核来管理和调度的，进程的切换只能发生在内核态，所以，进程的上下文切换不仅包括了用户空间的资源，也包括内核空间的资源 (4) 进程的上下文切换过程: (a) 接收到切换信号，挂起进程，记录当前进程虚拟内存、栈等资源存储 (b) 将这个进程在CPU中的上下文状态存储起来 (c) 然后在内存中检索下一个进程的上下文 (d) 并将其加载到CPU的寄存器中恢复 (e) 还需要刷新新进程的虚拟内存和用户栈 (f) 最后跳转到程序计数器所指向的位置(即跳转搭配进程被中断时的代码行)，以恢复改进程 (5) 下列将会触发进程上下文切换的场景: (a) 根据调度策略，将CPU时间划分为对应的时间片，当时间片耗尽时，当前进程必须挂起 (b) 资源不足的，在获取到足够资源之前进程挂起 (c) 进程sleep挂起进程 (d) 高优先级进程导致当前进度挂起 (e) 硬件中断，导致当前进程挂起7、线程上下文切换(1) 不通进程之前的线程上下文切换，其过程和进程上下文切换大致相同(2) 进程内部的线程上下文切换，不需要切换进程用户资源，只需要切换线程私有的数据和寄存器等，这会比进程上下文进程切换消耗的资源少，所以多线程相比多线程优势8、中断上下文切换快速响应硬件的事件，中断处理会打断进程的正常调度和执行，同一CPU内，硬件中断优先级高于进程。切换过程类似于系统调用，不涉及到用户运行态资源，但大量的中断上下文切换同样可能引发性能问题备注:系统调用属于上下文切换，分别是CPU用来存储指令和下一条要执行指令的寄存器 CPU上下文切换(下篇)123456789101112131415查看系统上下文切换情况:系统分析工具vmstat(vmstat是只给出了系统总体上下文切换情况，要想查看每个进程的详细情况，要向)![vmstat_5](https://i.loli.net/2019/03/05/5c7dd70b7cfc3.jpg)cs（context switch）是每秒上下文切换的次数。in（interrupt）则是每秒中断的次数。r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。b（Blocked）则是处于不可中断睡眠状态的进程数。###pidstat是查看每个进程上下文切换情况:（-w）每隔5秒输出1组数据![pidstat_5.jpg](https://i.loli.net/2019/03/05/5c7e40eb19730.jpg)解释:一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数， 另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。]]></content>
      <categories>
        <category>linux操作性能优化</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F25%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>linux命令</category>
        <category>awk高级</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
